Welcome to the official repository for our paper **"Large Language Models are Good Multi-lingual Learners: When LLMs Meet Cross-lingual Prompts"**, accepted at **COLING 2025**.

------

#### **Important Note**

This work was conducted during my time at a previous company, and due to restrictions, I am unable to open-source the code. However, to help the community understand our approach, I am providing the **slide deck** for this work. You can easily find and download the accompanying **PPT file** in this repository.

------

#### **Overview**

The core idea of this paper stems from the observation that **LLMs often struggle to adhere to complex rules**, especially in long prompts. During our research, we discovered that **translating error-prone rules into another language** improves the model's focus and performance.

Based on this insight, we proposed **MLPrompt**, a novel method that utilizes **multilingual context** to enhance rule adherence. Through experiments on **text2SQL** and **text2JSON** tasks, MLPrompt demonstrates significant improvements in accuracy and compliance with user-defined rules.

------

#### **Citation**

If you find this work useful for your research, please consider citing our paper:

```
@article{wang2024large,
  title={Large Language Models are Good Multi-lingual Learners: When LLMs Meet Cross-lingual Prompts},
  author={Wang, Teng and He, Zhenqi and Yu, Wing-Yin and Fu, Xiaojin and Han, Xiongwei},
  journal={arXiv preprint arXiv:2409.11056},
  year={2024}
}
```

------

#### **Acknowledgments**

Thank you for your interest in our work. If you have any questions or feedback, feel free to reach out or open an issue in this repository.