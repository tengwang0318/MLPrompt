Welcome to the official repository for our paper **"Large Language Models are Good Multi-lingual Learners: When LLMs Meet Cross-lingual Prompts"**, accepted at **COLING 2025**.

------

#### **Important Note**

This work was conducted during my time at a previous company, and due to restrictions, I am unable to open-source the code. However, to help the community understand our approach, I am providing the **slide deck** for this work. You can easily find and download the accompanying **PPT file** in this repository.

------

#### **Overview**

The core idea of this paper stems from the observation that **LLMs often struggle to adhere to complex rules**, especially in long prompts. During our research, we discovered that **translating error-prone rules into another language** improves the model's focus and performance.

Based on this insight, we proposed **MLPrompt**, a novel method that utilizes **multilingual context** to enhance rule adherence. Through experiments on **text2SQL** and **text2JSON** tasks, MLPrompt demonstrates significant improvements in accuracy and compliance with user-defined rules.

------

#### **Citation**

If you find this work useful for your research, please consider citing our paper:

```
@inproceedings{wang2025large,
  title={Large Language Models are good multi-lingual learners: When LLMs meet cross-lingual prompts},
  author={Wang, Teng and He, Zhenqi and Yu, Wing-Yin and Fu, Xiaojin and Han, Xiongwei},
  booktitle={Proceedings of the 31st International Conference on Computational Linguistics},
  pages={4442--4456},
  year={2025}
}
```

------

#### **Acknowledgments**

Thank you for your interest in our work. If you have any questions or feedback, feel free to reach out or open an issue in this repository.
